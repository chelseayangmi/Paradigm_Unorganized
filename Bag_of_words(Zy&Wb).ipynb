{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tqdm'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-7243529c1d53>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# Progress bar and delaying requests\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtnrange\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtqdm_notebook\u001b[0m \u001b[0;31m#progress bars\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mrandom\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrandint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tqdm'"
     ]
    }
   ],
   "source": [
    "## Import Packages and Libraries ##\n",
    "\n",
    "# Web parcing, scraping, etc.\n",
    "import bs4 as bs # BeautifulSoup4 \n",
    "import urllib3\n",
    "import re\n",
    "import requests # HTTP parser\n",
    "import html5lib\n",
    "\n",
    "# DataFrames and math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Output related packages \n",
    "import pprint as pp\n",
    "import json\n",
    "\n",
    "# Progress bar and delaying requests \n",
    "from tqdm import tnrange, tqdm_notebook #progress bars\n",
    "from random import randint\n",
    "import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# stretch Jupyter coding blocks to fit screen\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\")) \n",
    "\n",
    "# make it run on py2 and py3\n",
    "from __future__ import division, print_function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Mining I\n",
    "This  notebook is intended to perform the following processes:\n",
    "\n",
    "    1.1 Read-in news articles from newsAPI for a given date range, and up to five queries (passed as a list).\n",
    "\n",
    "    1.2 Extract features native to the articles (e.g. url).\n",
    "\n",
    "    1.3 Perform data cleanup and preprocessing.\n",
    "\n",
    "    1.4 Split dataset into n-csv-files for distrubuted computation or batching."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Documentation__\n",
    "\n",
    "newsAPI (https://newsapi.org/) has limited documentation as to how their backend works. However, when developing this notebook the following website was frequently referenced -- as their documentation appears to closely match the behavior of newsAPI. \n",
    "\n",
    "https://docs.aylien.com/newsapi/#getting-started\n",
    "\n",
    "Moreover, here is the user agreement:\n",
    "\n",
    "https://newsapi.org/terms\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### **Begin Data Mining I:** Read-in NewsAPI feed for a given date range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'newsapi.newsapi_client.NewsApiClient'>\n"
     ]
    }
   ],
   "source": [
    "### NEWSAPI RELATED ###\n",
    "# keys: \n",
    "#rhkey = '847446b32283474fafd2aec7f95e502b'\n",
    "#r1key  = '1da951c142304f7bab52ba8e3970495b'\n",
    "#r2key = '40d53e49ee3543a3b162e6a453e2e373'\n",
    "#m1key = '211fc2107848473e99c1f235b400a07f'\n",
    "#m2key = 'c0f99eab932d4cabb61c23239f3f482d'\n",
    "m3key = '658cd65a714349fdbb7e8dd6ce59e9c4'\n",
    "#m4key  = '8ba091b7a47b4c9a9162a83ca72eb1ca'\n",
    "#e1key  = '2bc85776a0c14af6b9937366ad683e2f'\n",
    "#e2key = '22e5c3a8f0ee4fa59aaf384ba9395a86'\n",
    "#e3key = 'c554f8fb27ca4be1862192b44ee4425d'\n",
    "\n",
    "\n",
    "# Install API \n",
    "# !pip install newsapi-python\n",
    "\n",
    "# Import Client\n",
    "from newsapi import NewsApiClient\n",
    "\n",
    "# Initialize Client (create object)\n",
    "news_api = NewsApiClient(api_key = m3key)\n",
    "print(type(news_api))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__1.1 Read-in news articles from newsAPI for a given date range__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function: **get_news**\n",
    "Function establishes values to be used for control of loop then calls functions used to extract news article data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_news(query, start, stop, sort, lang, article_count, page_count, init):\n",
    "    \"\"\"\n",
    "    control function for iterating over 100 pages of newsAPI's content \n",
    "    function then controls subordinate fuctions that extract ~100 articles per each page\n",
    "    \"\"\"\n",
    "    \n",
    "    import math\n",
    "    import time  \n",
    "    \n",
    "    # extract information about response file to ensure proper loop control\n",
    "    params = get_params(query, start, stop, sort, lang, article_count, page_count)\n",
    "\n",
    "    # variable referencing\n",
    "    status = params['status']\n",
    "    results = params['totalResults']\n",
    "\n",
    "    # Confirmation of data extraction\n",
    "    print(\"\\nVerify Read-in Process:\", status)\n",
    "    print(\"Number of Articles Correctly Read: \", results)\n",
    "    print(type(params), params.keys())\n",
    "           \n",
    "    # per page article extraction stop variable -- if number of articles is greater than number articles per page\n",
    "    loops = math.ceil(results/article_count)\n",
    "    \n",
    "    # batching control\n",
    "    begin = 0 + init\n",
    "    terminate = article_count + init\n",
    "    print(\"Total number of iterations (pages):\",loops)\n",
    "    \n",
    "    # check to ensure loop does not extract over 100pages*100endpoints=10000 articles\n",
    "    if loops < terminate:\n",
    "        terminate = loops\n",
    "        \n",
    "    print(\"Page range being extracted\", begin, terminate)\n",
    "    \n",
    "    if page_count == 'all' or article_count <  results:\n",
    "        print(\"\\n\\nExtracting News Data...\\n\")\n",
    "        full_df = pd.DataFrame()\n",
    "    \n",
    "        # function is called withinin while, is subject to number of pages available as a function of total no. articles\n",
    "        while begin < terminate:\n",
    "            begin += 1\n",
    "            page = begin  # for referencing clarity\n",
    "            \n",
    "            ### newsAPI has MAX HIT LIMIT of 60 per minute ### \n",
    "            time.sleep(1)   # delay of 1 second\n",
    "            print(\"Extracting Page\", page)\n",
    "\n",
    "            # call sequencial pages of articles and appends to df\n",
    "            df = news_data(query, start, stop, sort, lang, article_count, page)\n",
    "            full_df = full_df.append(df, ignore_index = True)\n",
    "            \n",
    "        print('Batch extraction completed:',begin,'of',terminate)\n",
    "        return(full_df)            \n",
    "    else:\n",
    "        # extracts articles assuming articles >= pages\n",
    "        print(\"Possible Invalid Parameters: Check values\")\n",
    "        brief_df = news_api.get_everything(q = query,\n",
    "                                          from_parameter= start,\n",
    "                                          to= stop,\n",
    "                                          sort_by= sort,\n",
    "                                          language= lang,\n",
    "                                          page_size= int(article_count)\n",
    "                                         )\n",
    "        return(brief_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function: **get_params**\n",
    "Function runs an initial newsAPI call, used to store values for controlling loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_params(query, start, stop, sort, lang, article_count, page_count):\n",
    "    \"\"\"\n",
    "    function accepts similar parameters to master function get_news.\n",
    "    get_params is used to extract parameters to be used in controlling other functions \n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\nExtracting Parameters for newsAPI...\\n\")\n",
    "    params = news_api.get_everything(q = query,\n",
    "                                     from_param= start,\n",
    "                                     to= stop,\n",
    "                                     sort_by= sort,\n",
    "                                     language= lang,\n",
    "                                     page_size= int(article_count)\n",
    "                                    )\n",
    "    \n",
    "    # Confirmation of data extraction\n",
    "    print(\"Read-in Status of Given Date Range:\", params['status'])\n",
    "    print(\"Number of Articles in Given Date Range: \", params['totalResults'])\n",
    "    \n",
    "    return(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function: **news_data**\n",
    "Function handles cases, and extracts values within 'articles'. Returns dataframe of contents: \n",
    "\n",
    "\n",
    "*Index(['author', 'description', 'publishedAt', 'source', 'title', 'url','urlToImage'],dtype='object')*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def news_data(query, start, stop, sort, lang, article_count, page):\n",
    "    \"\"\"\n",
    "    Principal data extraction function - can handle various relationships between no.pages and no.articles \n",
    "    \"\"\"\n",
    "    \n",
    "    if isinstance(page, int):\n",
    "        params = news_api.get_everything(q = query,\n",
    "                                         from_param= start,\n",
    "                                         to= stop,\n",
    "                                         sort_by= sort,\n",
    "                                         language= lang,\n",
    "                                         page_size= int(article_count),\n",
    "                                         page = int(page)\n",
    "                                        )\n",
    "    ########### if params['articles'] throws error ########### \n",
    "    # either endpoint limit was met (10000)                  #\n",
    "    # too many endpoint requests in a month (1000 per month) #\n",
    "    # change to new api key.                                 #\n",
    "    ##########################################################\n",
    "    return(pd.DataFrame(params['articles'])) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### User provided parameters and function call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#01/26/18 to 03/26/18\n",
    "query = 'Bitcoin'         # can handle a list of up to five search topics\n",
    "start = '2018-09-17'      # yyyy-mm-dd\n",
    "stop  = '2018-09-23'\n",
    "sort  = 'publishedAt'\n",
    "lang  = 'en'\n",
    "article_count = 20       # default is 20\n",
    "page_count = 'all'        # enter 1, 2, ... Notes: 'all' iterates over all articLes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "---\n",
    "#### __NOTE__\n",
    "\n",
    "Since newsAPI has a daily limit of endpoint requests (1000 per day), batching needs to be implemented.  The following cells controls the initialization for subsequent cells -- to ensure appropropriate, and sequential article extraction.\n",
    "\n",
    "Also, webAPI has a limit of 10,000 articles per key -- unless you want to pay for the monthly access.\n",
    "___\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ---------------------------------------------------------------------------- ##\n",
    "## KEY: Initialize accroding to batch number (i.e. n*100, where n is the batch) ##\n",
    "## USE: n > 0 ---- only once we can extract above 10000 articles\n",
    "n = 0\n",
    "init = n*100\n",
    "## ---------------------------------------------------------------------------- ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting Parameters for newsAPI...\n",
      "\n",
      "Read-in Status of Given Date Range: ok\n",
      "Number of Articles in Given Date Range:  1085\n",
      "\n",
      "Verify Read-in Process: ok\n",
      "Number of Articles Correctly Read:  1085\n",
      "<class 'dict'> dict_keys(['status', 'totalResults', 'articles'])\n",
      "Total number of iterations (pages): 55\n",
      "Page range being extracted 0 20\n",
      "\n",
      "\n",
      "Extracting News Data...\n",
      "\n",
      "Extracting Page 1\n",
      "Extracting Page 2\n",
      "Extracting Page 3\n",
      "Extracting Page 4\n",
      "Extracting Page 5\n",
      "Extracting Page 6\n",
      "Extracting Page 7\n",
      "Extracting Page 8\n",
      "Extracting Page 9\n",
      "Extracting Page 10\n",
      "Extracting Page 11\n",
      "Extracting Page 12\n",
      "Extracting Page 13\n",
      "Extracting Page 14\n",
      "Extracting Page 15\n",
      "Extracting Page 16\n",
      "Extracting Page 17\n",
      "Extracting Page 18\n",
      "Extracting Page 19\n",
      "Extracting Page 20\n",
      "Batch extraction completed: 20 of 20\n"
     ]
    }
   ],
   "source": [
    "# object is the result of the following functions: 'get_params', 'get_news', and 'get_data'\n",
    "news = get_news(query, start, stop, sort, lang, article_count, page_count, init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explore nested key/value pairs from newsAPI data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['author', 'content', 'description', 'publishedAt', 'source', 'title',\n",
       "       'url', 'urlToImage'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## ENSURE API WAS ACCESSED ##\n",
    "# if news.keys includes 'author', 'description', etc., success!\n",
    "\n",
    "news.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400\n",
      "Index(['author', 'content', 'description', 'publishedAt', 'source', 'title',\n",
      "       'url', 'urlToImage'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "399"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(news))\n",
    "print(news.keys())\n",
    "news.head(5)\n",
    "len(news['url'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__1.2 Extract features native to the articles__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function: **get_info**\n",
    "Function extracts variables from dataframe and stores each as a list, returning all of them as a single dataframe.\n",
    "\n",
    "__Note:__ *urlToImage* is not included in this process, as we are uncertain as to the value of the feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_info(df):\n",
    "    \"\"\"\n",
    "    Accepts a dataframe of newsAPI articles, and controls all subbordinate functions that preprocess data\n",
    "    \"\"\"\n",
    "    \n",
    "    import copy\n",
    "    \n",
    "    author = []\n",
    "    title = []\n",
    "    publisher = []\n",
    "    publish_url = []\n",
    "    timeStamp = []\n",
    "    description = []\n",
    "    \n",
    "    # loop appends rows to respective lists \n",
    "    for col_name in df:\n",
    "        for index in df[col_name]:\n",
    "            if col_name == 'author':\n",
    "                author.append(index)\n",
    "            elif col_name == 'title':\n",
    "                title.append(index)\n",
    "            elif col_name == 'source':\n",
    "                name = index['name']\n",
    "                publisher.append(name)\n",
    "            elif col_name == 'url':\n",
    "                publish_url.append(index)\n",
    "            elif col_name == 'publishedAt':\n",
    "                timeStamp.append(index)\n",
    "            elif col_name == 'description':\n",
    "                description.append(index)\n",
    "            else:\n",
    "                continue\n",
    "    \n",
    "    # merge lists and return them as dataframe.\n",
    "    df = pd.DataFrame({'author' : author,\n",
    "                       'title' : title,\n",
    "                       'publisher' : publisher,\n",
    "                       'source_url' : publish_url,\n",
    "                       'timeStamp' : timeStamp,\n",
    "                       'description' : description})\n",
    "    \n",
    "    return(df)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Completed newsAPI Read-in Process: \n",
    "##### newsDF contains features extracted from raw newsAPI feed, for a given data range, and query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Object creation\n",
    "newsDF = get_info(news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame Dimensions: (400, 6) \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>publisher</th>\n",
       "      <th>source_url</th>\n",
       "      <th>timeStamp</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Yashu Gola</td>\n",
       "      <td>Content Creators on YouTube, Twitch, and Wikip...</td>\n",
       "      <td>Crypto Coins News</td>\n",
       "      <td>https://www.ccn.com/content-creators-on-youtub...</td>\n",
       "      <td>2018-09-22T23:30:12Z</td>\n",
       "      <td>Content creators on the internet will now be a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BetaList</td>\n",
       "      <td>COINiD – The next generation Bitcoin wallet th...</td>\n",
       "      <td>Betalist.com</td>\n",
       "      <td>https://betalist.com/startups/coinid</td>\n",
       "      <td>2018-09-22T22:31:52Z</td>\n",
       "      <td>The next generation Bitcoin wallet that suppor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>David Cottle, Analyst, David Cottle</td>\n",
       "      <td>Australian Dollar Gains May Be Stymied By Fed ...</td>\n",
       "      <td>Dailyfx.com</td>\n",
       "      <td>https://www.dailyfx.com/forex/fundamental/fore...</td>\n",
       "      <td>2018-09-22T22:00:00Z</td>\n",
       "      <td>The Australian Dollar has had a rare run of ga...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                author  \\\n",
       "0                           Yashu Gola   \n",
       "1                             BetaList   \n",
       "2  David Cottle, Analyst, David Cottle   \n",
       "\n",
       "                                               title          publisher  \\\n",
       "0  Content Creators on YouTube, Twitch, and Wikip...  Crypto Coins News   \n",
       "1  COINiD – The next generation Bitcoin wallet th...       Betalist.com   \n",
       "2  Australian Dollar Gains May Be Stymied By Fed ...        Dailyfx.com   \n",
       "\n",
       "                                          source_url             timeStamp  \\\n",
       "0  https://www.ccn.com/content-creators-on-youtub...  2018-09-22T23:30:12Z   \n",
       "1               https://betalist.com/startups/coinid  2018-09-22T22:31:52Z   \n",
       "2  https://www.dailyfx.com/forex/fundamental/fore...  2018-09-22T22:00:00Z   \n",
       "\n",
       "                                         description  \n",
       "0  Content creators on the internet will now be a...  \n",
       "1  The next generation Bitcoin wallet that suppor...  \n",
       "2  The Australian Dollar has had a rare run of ga...  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verifying correct data extraction\n",
    "print(\"\\nDataFrame Dimensions:\", newsDF.shape, \"\\n\")\n",
    "newsDF.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__1.3 Perform data cleanup and preprocessing.__\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following functions perform basic clean up on a dataframe. The purpose is to prepare the file to write-out (csv).  \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace 'None' values\n",
    "def findNone(df):\n",
    "    \"\"\"\n",
    "     Receives pandas datraframe, and removes null entries from author feature\n",
    "    \"\"\"\n",
    "    print(\"Removed 'None' values in author feature...\")\n",
    "    author = df['author']\n",
    "    publisher = df['publisher']\n",
    "    \n",
    "    for i in range(len(df)):\n",
    "        if pd.isnull(author.loc[i]):\n",
    "            author.loc[i] = publisher.loc[i]\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove gaps \n",
    "def gapStrip(df):\n",
    "    \"\"\"\n",
    "    Receives pandas dataframe and leading and traling empty space`\n",
    "    \"\"\"\n",
    "    df.columns = map(str.strip, df.columns) \n",
    "    print(\"Removed leading and trailing spaces and tabs...\")\n",
    "    # element-wise operation\n",
    "    f = lambda x: x.strip() if (isinstance(x,str)) else x\n",
    "    df = df.applymap(f)\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize time stamps\n",
    "def std_timeStamp(df):\n",
    "    \"\"\"\n",
    "    Receives pandas dataframe and standardizes time stamps \n",
    "    \"\"\"\n",
    "    import datetime\n",
    "    # Check to see time stamps are in zero timezones\n",
    "    print(\"Converted Time Stamps to Desired Standard Formating...\")\n",
    "    for time in df['timeStamp']:\n",
    "        if time.endswith('Z'):\n",
    "            df['timeStamp'] = pd.to_datetime(df['timeStamp'],\n",
    "                                             infer_datetime_format = True,\n",
    "                                             utc = True)                       # returns a type '.Timestamp'\n",
    "            return(df)\n",
    "        else:\n",
    "            print(\"Revisit appropriate variable or function to deal with time zones that are not zero\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_clean(df):\n",
    "    \"\"\"\n",
    "    Performs Generic Cleanup and Preprocessing on a given dataframe sourced from newsAPI\n",
    "    \"\"\"\n",
    "    \n",
    "    temp = findNone(df)           # removes missing values from author column\n",
    "    temp2 = gapStrip(temp)        # remove leading and trailing white space\n",
    "    temp3 = std_timeStamp(temp2)  # convert time stamps to 'utc' standard\n",
    "    return(temp3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 'None' values in author feature...\n",
      "Removed leading and trailing spaces and tabs...\n",
      "Converted Time Stamps to Desired Standard Formating...\n"
     ]
    }
   ],
   "source": [
    "riskEx_df = feature_clean(newsDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                                author  \\\n",
       " 0                           Yashu Gola   \n",
       " 1                             BetaList   \n",
       " 2  David Cottle, Analyst, David Cottle   \n",
       " 3                        Conor Maloney   \n",
       " 4                        Cole Petersen   \n",
       " \n",
       "                                                title          publisher  \\\n",
       " 0  Content Creators on YouTube, Twitch, and Wikip...  Crypto Coins News   \n",
       " 1  COINiD – The next generation Bitcoin wallet th...       Betalist.com   \n",
       " 2  Australian Dollar Gains May Be Stymied By Fed ...        Dailyfx.com   \n",
       " 3  Bitcoin ATM CEO: Cryptocurrency Needs Regulati...  Crypto Coins News   \n",
       " 4  Brazil’s Biggest Brokerage is Officially Joini...        Newsbtc.com   \n",
       " \n",
       "                                           source_url  \\\n",
       " 0  https://www.ccn.com/content-creators-on-youtub...   \n",
       " 1               https://betalist.com/startups/coinid   \n",
       " 2  https://www.dailyfx.com/forex/fundamental/fore...   \n",
       " 3  https://www.ccn.com/bitcoin-atm-ceo-cryptocurr...   \n",
       " 4  https://www.newsbtc.com/2018/09/22/brazils-big...   \n",
       " \n",
       "                   timeStamp                                        description  \n",
       " 0 2018-09-22 23:30:12+00:00  Content creators on the internet will now be a...  \n",
       " 1 2018-09-22 22:31:52+00:00  The next generation Bitcoin wallet that suppor...  \n",
       " 2 2018-09-22 22:00:00+00:00  The Australian Dollar has had a rare run of ga...  \n",
       " 3 2018-09-22 21:57:58+00:00  In an exclusive interview with CCN, the CEO of...  \n",
       " 4 2018-09-22 21:30:38+00:00  Brazil’s largest independent brokerage is the ...  ,\n",
       "                                                 author  \\\n",
       " 395                                     Dalmas Ngetich   \n",
       " 396                                      Omkar Godbole   \n",
       " 397                                    Jonathan Garber   \n",
       " 398  https://www.facebook.com/profile.php?id=100009...   \n",
       " 399                                      Martin Beltov   \n",
       " \n",
       "                                                  title              publisher  \\\n",
       " 395  The $234 Billion Money Laundering Case at Dans...            Newsbtc.com   \n",
       " 396  Bitcoin Price Sees High-Volume Recovery From F...           Coindesk.com   \n",
       " 397  10 things you need to know before the opening ...       Business Insider   \n",
       " 398  $60 Million Hacked from Zaif Cryptocurrency Ex...               Newsweek   \n",
       " 399  CVE-2018-17144: Bitcoin Core Vulnerability Cou...  Securityboulevard.com   \n",
       " \n",
       "                                             source_url  \\\n",
       " 395  https://www.newsbtc.com/2018/09/20/danske-bank...   \n",
       " 396  https://www.coindesk.com/bitcoin-price-sees-hi...   \n",
       " 397  https://www.businessinsider.com/stock-market-n...   \n",
       " 398  https://www.newsweek.com/60-million-hacked-zai...   \n",
       " 399  https://securityboulevard.com/2018/09/cve-2018...   \n",
       " \n",
       "                     timeStamp  \\\n",
       " 395 2018-09-20 11:00:54+00:00   \n",
       " 396 2018-09-20 11:00:38+00:00   \n",
       " 397 2018-09-20 10:45:00+00:00   \n",
       " 398 2018-09-20 10:44:24+00:00   \n",
       " 399 2018-09-20 10:40:05+00:00   \n",
       " \n",
       "                                            description  \n",
       " 395  This week, Danish publications reported that D...  \n",
       " 396  Bitcoin's rebound from the five-week low of $6...  \n",
       " 397  Here is what you need to know. China is report...  \n",
       " 398  The hack follows several heists in the country...  \n",
       " 399  The Bitcoin Core software has been patched to ...  )"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensure data was preprocessed\n",
    "riskEx_df.head(5), riskEx_df.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 400 entries, 0 to 399\n",
      "Data columns (total 6 columns):\n",
      "author         400 non-null object\n",
      "title          400 non-null object\n",
      "publisher      400 non-null object\n",
      "source_url     400 non-null object\n",
      "timeStamp      400 non-null datetime64[ns, UTC]\n",
      "description    399 non-null object\n",
      "dtypes: datetime64[ns, UTC](1), object(5)\n",
      "memory usage: 18.8+ KB\n"
     ]
    }
   ],
   "source": [
    "## Check file size\n",
    "riskEx_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__1.4 Write out to csv.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write out n-csv-files each with 100 rows. Process is done to reduce computational load\n",
    "riskEx_df.to_csv('rawData_test1008.csv', index_label = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "383"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('rawData_test1008.csv')\n",
    "#print(df.info())\n",
    "print(len(df))\n",
    "len(df['description'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['description'].dropna(axis = 0,inplace = True)\n",
    "# df[df['description'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "author                                                  alexmark\n",
       "title          $TLRY is the perfect example of why there is n...\n",
       "publisher                                Investmentwatchblog.com\n",
       "source_url     http://www.investmentwatchblog.com/tlry-is-the...\n",
       "timeStamp                              2018-09-21 00:29:07+00:00\n",
       "description                                                  NaN\n",
       "Name: 241, dtype: object"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df[df['description'].isnull()]\n",
    "df.iloc[241,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_of_words = vectorizer.fit(df['description'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_of_words = vectorizer.transform(df['description'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>0027</th>\n",
       "      <th>03</th>\n",
       "      <th>07</th>\n",
       "      <th>09</th>\n",
       "      <th>0rc4</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>105</th>\n",
       "      <th>10yr</th>\n",
       "      <th>...</th>\n",
       "      <th>œi</th>\n",
       "      <th>一职</th>\n",
       "      <th>一職</th>\n",
       "      <th>以及在加密市場中的定位</th>\n",
       "      <th>何謂場外交易</th>\n",
       "      <th>作者</th>\n",
       "      <th>担任</th>\n",
       "      <th>擔任</th>\n",
       "      <th>目前任职美国硅谷创投</th>\n",
       "      <th>目前任職美國矽谷創投</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3253 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   000  0027  03  07  09  0rc4  10  100  105  10yr     ...      œi  一职  一職  \\\n",
       "0    0     0   0   0   0     0   0    0    0     0     ...       0   0   0   \n",
       "1    0     0   0   0   0     0   0    0    0     0     ...       0   0   0   \n",
       "2    0     0   0   0   0     0   0    0    0     0     ...       0   0   0   \n",
       "3    0     0   0   0   0     0   0    0    0     0     ...       0   0   0   \n",
       "4    0     0   0   0   0     0   0    0    0     0     ...       0   0   0   \n",
       "\n",
       "   以及在加密市場中的定位  何謂場外交易  作者  担任  擔任  目前任职美国硅谷创投  目前任職美國矽谷創投  \n",
       "0            0       0   0   0   0           0           0  \n",
       "1            0       0   0   0   0           0           0  \n",
       "2            0       0   0   0   0           0           0  \n",
       "3            0       0   0   0   0           0           0  \n",
       "4            0       0   0   0   0           0           0  \n",
       "\n",
       "[5 rows x 3253 columns]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordss = pd.DataFrame(bag_of_words.toarray(), columns=vectorizer.get_feature_names())\n",
    "wordss.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggg = wordss.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "the               709\n",
       "of                332\n",
       "to                299\n",
       "and               279\n",
       "in                230\n",
       "bitcoin           170\n",
       "on                164\n",
       "is                162\n",
       "for               129\n",
       "that              119\n",
       "has               116\n",
       "cryptocurrency    112\n",
       "it                 92\n",
       "by                 89\n",
       "with               84\n",
       "are                71\n",
       "this               70\n",
       "from               70\n",
       "as                 69\n",
       "have               68\n",
       "exchange           65\n",
       "its                63\n",
       "new                58\n",
       "an                 57\n",
       "at                 55\n",
       "be                 54\n",
       "crypto             53\n",
       "was                49\n",
       "been               48\n",
       "blockchain         47\n",
       "                 ... \n",
       "glyph               1\n",
       "glorious            1\n",
       "safety              1\n",
       "saga                1\n",
       "game                1\n",
       "gamescom            1\n",
       "gaming              1\n",
       "gardner             1\n",
       "garza               1\n",
       "gauges              1\n",
       "gavin               1\n",
       "gaw                 1\n",
       "gaze                1\n",
       "gbp                 1\n",
       "gdp                 1\n",
       "generally           1\n",
       "giving              1\n",
       "safeguard           1\n",
       "gentleman           1\n",
       "safe                1\n",
       "sacrifice           1\n",
       "sacramento          1\n",
       "gi                  1\n",
       "sabot               1\n",
       "giants              1\n",
       "giddy               1\n",
       "gift                1\n",
       "s9i                 1\n",
       "given               1\n",
       "目前任職美國矽谷創投          1\n",
       "Length: 3253, dtype: int64"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordss.sum().sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['the', 'of', 'to', 'and', 'in', 'bitcoin', 'on', 'is', 'for', 'that',\n",
       "       ...\n",
       "       'sacrifice', 'sacramento', 'gi', 'sabot', 'giants', 'giddy', 'gift',\n",
       "       's9i', 'given', '目前任職美國矽谷創投'],\n",
       "      dtype='object', length=3253)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gg = wordss.sum().sort_values(ascending = False).index\n",
    "gg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(wordss.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtt = wordss.sum().to_frame(\"freq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>an</th>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>and</th>\n",
       "      <td>279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>are</th>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>as</th>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>at</th>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>be</th>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bitcoin</th>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>by</th>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>crypto</th>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cryptocurrency</th>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exchange</th>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>for</th>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>from</th>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>has</th>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>have</th>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in</th>\n",
       "      <td>230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is</th>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>it</th>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>its</th>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new</th>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>of</th>\n",
       "      <td>332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>on</th>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>that</th>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>this</th>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>with</th>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                freq\n",
       "an                57\n",
       "and              279\n",
       "are               71\n",
       "as                69\n",
       "at                55\n",
       "be                54\n",
       "bitcoin          170\n",
       "by                89\n",
       "crypto            53\n",
       "cryptocurrency   112\n",
       "exchange          65\n",
       "for              129\n",
       "from              70\n",
       "has              116\n",
       "have              68\n",
       "in               230\n",
       "is               162\n",
       "it                92\n",
       "its               63\n",
       "new               58\n",
       "of               332\n",
       "on               164\n",
       "that             119\n",
       "the              709\n",
       "this              70\n",
       "to               299\n",
       "with              84"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtt[dtt['freq']>50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bitcoin</th>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cryptocurrency</th>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exchange</th>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new</th>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>crypto</th>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blockchain</th>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>digital</th>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>week</th>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>said</th>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>market</th>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cryptocurrencies</th>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>one</th>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thursday</th>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mining</th>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zaif</th>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price</th>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>security</th>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>company</th>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>million</th>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last</th>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ripple</th>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>firm</th>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>could</th>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tech</th>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first</th>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>billion</th>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>money</th>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>japanese</th>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>based</th>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>friday</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>world</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worth</th>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>novogratz</th>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stolen</th>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>management</th>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hackers</th>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>investors</th>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>report</th>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>news</th>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>technology</th>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>back</th>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>two</th>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sept</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prices</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>september</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>japan</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>currency</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  freq\n",
       "bitcoin            170\n",
       "cryptocurrency     112\n",
       "exchange            65\n",
       "new                 58\n",
       "crypto              53\n",
       "blockchain          47\n",
       "digital             44\n",
       "week                44\n",
       "said                41\n",
       "market              39\n",
       "cryptocurrencies    34\n",
       "one                 28\n",
       "thursday            27\n",
       "mining              27\n",
       "zaif                27\n",
       "price               27\n",
       "security            26\n",
       "company             26\n",
       "million             26\n",
       "last                25\n",
       "ripple              25\n",
       "firm                24\n",
       "2018                24\n",
       "could               22\n",
       "tech                22\n",
       "first               22\n",
       "billion             21\n",
       "money               21\n",
       "japanese            21\n",
       "based               21\n",
       "year                20\n",
       "time                20\n",
       "friday              20\n",
       "world               20\n",
       "worth               19\n",
       "novogratz           19\n",
       "stolen              19\n",
       "management          19\n",
       "60                  18\n",
       "hackers             18\n",
       "investors           18\n",
       "report              18\n",
       "news                18\n",
       "technology          18\n",
       "20                  18\n",
       "back                17\n",
       "two                 17\n",
       "sept                16\n",
       "prices              16\n",
       "september           16\n",
       "japan               16\n",
       "currency            16"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered = [w for w in gg if not w in stop_words]\n",
    "freqs = wordss[filtered].sum().to_frame(\"freq\")\n",
    "freqs[freqs['freq']>15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Note:__ if wanting to create batches of raw data files containing n-articles, use the following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def df_to_csvs(df):\n",
    "#    articlesPage = int(100)\n",
    "#    totalArticles = len(df)\n",
    "#    batchSize=round(totalArticles/articlesPage)          # number of rows in single output file\n",
    "        \n",
    "#    for id, df_i in  enumerate(np.array_split(df, batchSize)):\n",
    "#        df_i.to_csv('rawData_{id}.csv'.format(id=id), index_label = False)                 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **End Data Mining I:** Read-in NewsAPI feed for a given date range\n",
    "___"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
